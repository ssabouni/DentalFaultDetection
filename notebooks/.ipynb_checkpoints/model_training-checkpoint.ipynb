{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dea46fdb-9460-4d89-aec7-63fd01f0f295",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba6d47d8-286f-4e2f-bce7-f488a97e0212",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ TRAIN SET: 321 images, 776 annotations.\n",
      "ðŸ“‚ VALID SET: 20 images, 71 annotations.\n",
      "ðŸ“‚ TEST SET: 20 images, 53 annotations.\n",
      "\n",
      "Bounding Box Count Per Class:\n",
      "insufficient light body: 426\n",
      "uneven finish line: 278\n",
      "non-continuous finish line: 92\n",
      "void: 65\n",
      "tear: 39\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# Define paths for train, valid, and test datasets\n",
    "base_dir = \"../data\"\n",
    "subsets = [\"train\", \"valid\", \"test\"]\n",
    "\n",
    "# Global dictionaries\n",
    "class_counts = Counter()\n",
    "categories = {}  # To store category names\n",
    "annotations = {}\n",
    "\n",
    "# Function to process datasets\n",
    "def process_dataset(subset):\n",
    "    global categories  # Ensure global access\n",
    "    image_dir = os.path.join(base_dir, subset)\n",
    "    annotation_file = os.path.join(image_dir, \"_annotations.coco.json\")\n",
    "\n",
    "    if not os.path.exists(annotation_file):\n",
    "        print(f\"âš ï¸ Annotation file missing: {annotation_file}\")\n",
    "        return\n",
    "\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    images = {img['id']: img for img in coco_data['images']}\n",
    "    annotations = coco_data['annotations']\n",
    "\n",
    "    # Initialize categories only once\n",
    "    if not categories:\n",
    "        categories = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
    "\n",
    "    # Count bounding boxes per class\n",
    "    for ann in annotations:\n",
    "        class_counts[ann['category_id']] += 1\n",
    "\n",
    "    print(f\"ðŸ“‚ {subset.upper()} SET: {len(images)} images, {len(annotations)} annotations.\")\n",
    "\n",
    "# Run for all subsets\n",
    "for subset in subsets:\n",
    "    process_dataset(subset)\n",
    "\n",
    "# Print bounding box count per class\n",
    "print(\"\\nBounding Box Count Per Class:\")\n",
    "for class_id, count in class_counts.items():\n",
    "    class_name = categories.get(class_id, \"Unknown\")\n",
    "    print(f\"{class_name}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa484ac-a9ad-4aa9-9936-55e65106e02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 06:32:10.312446: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 776 training annotations.\n",
      "Loaded 71 validation annotations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 06:32:20.447594: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes (including background): 6\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 640, 640, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 640, 640, 32  896         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 320, 320, 32  0           ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 320, 320, 64  18496       ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 160, 160, 64  0          ['conv2d_1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 160, 160, 12  73856       ['max_pooling2d_1[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 128)         0           ['conv2d_2[0][0]']               \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          33024       ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " bbox (Dense)                   (None, 32)           8224        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 48)           12336       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 8, 4)         0           ['bbox[0][0]']                   \n",
      "                                                                                                  \n",
      " class (Reshape)                (None, 8, 6)         0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 146,832\n",
      "Trainable params: 146,832\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "1/9 [==>...........................] - ETA: 3:24 - loss: 16522.7812 - reshape_loss: 16520.9902 - class_loss: 1.7906 - reshape_mae: 59.5277 - class_accuracy: 0.1375"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import cv2\n",
    "\n",
    "# Set base directory\n",
    "base_dir = \"../data\"\n",
    "\n",
    "# Define paths for images and annotations\n",
    "train_image_dir = os.path.join(base_dir, \"train\")\n",
    "valid_image_dir = os.path.join(base_dir, \"valid\")\n",
    "\n",
    "train_annotation_file = os.path.join(train_image_dir, \"_annotations.coco.json\")\n",
    "val_annotation_file = os.path.join(valid_image_dir, \"_annotations.coco.json\")\n",
    "\n",
    "# Load annotations\n",
    "def load_annotations(annotation_file):\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "train_annotations = load_annotations(train_annotation_file)\n",
    "val_annotations = load_annotations(val_annotation_file)\n",
    "\n",
    "print(f\"Loaded {len(train_annotations['annotations'])} training annotations.\")\n",
    "print(f\"Loaded {len(val_annotations['annotations'])} validation annotations.\")\n",
    "\n",
    "# Data Generator Class\n",
    "class ObjectDetectionDataGenerator(Sequence):\n",
    "    def __init__(self, annotations, image_dir, batch_size=32, shuffle=True, max_objects=8):\n",
    "        self.image_dir = image_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.max_objects = max_objects  # Use a fixed max_objects\n",
    "\n",
    "        # Build a dictionary for image filenames\n",
    "        self.img_id_to_filename = {img['id']: img['file_name'] for img in annotations['images']}\n",
    "        self.annotations_by_image = {}\n",
    "\n",
    "        for ann in annotations['annotations']:\n",
    "            image_id = ann['image_id']\n",
    "            if image_id not in self.annotations_by_image:\n",
    "                self.annotations_by_image[image_id] = []\n",
    "            \n",
    "            # Keep the original category IDs\n",
    "            self.annotations_by_image[image_id].append(ann)\n",
    "\n",
    "        # List of unique image IDs\n",
    "        self.image_ids = list(self.annotations_by_image.keys())\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_ids = self.image_ids[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        images, boxes, classes = [], [], []\n",
    "\n",
    "        for image_id in batch_ids:\n",
    "            image_path = os.path.join(self.image_dir, self.img_id_to_filename[image_id])\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  \n",
    "\n",
    "            if image is None:\n",
    "                print(f\"Warning: Skipping missing image {image_path}\")\n",
    "                continue\n",
    "\n",
    "            image = image.astype(np.float32) / 255.0  \n",
    "\n",
    "            images.append(image)\n",
    "\n",
    "            # Get bounding boxes and categories\n",
    "            b = np.array([ann['bbox'] for ann in self.annotations_by_image[image_id]], dtype=np.float32)  \n",
    "            c = np.array([ann['category_id'] for ann in self.annotations_by_image[image_id]], dtype=np.int32)  \n",
    "\n",
    "            # Ensure we don't exceed max_objects\n",
    "            if len(b) > self.max_objects:\n",
    "                b = b[:self.max_objects]  # Truncate excess boxes\n",
    "                c = c[:self.max_objects]\n",
    "\n",
    "            # Ensure correct shape by padding\n",
    "            b = np.pad(b, ((0, max(0, self.max_objects - len(b))), (0, 0)), mode='constant', constant_values=0)\n",
    "            c = np.pad(c, (0, max(0, self.max_objects - len(c))), mode='constant', constant_values=0)\n",
    "\n",
    "            boxes.append(b)\n",
    "            classes.append(c)\n",
    "\n",
    "        return np.array(images), (np.array(boxes), np.array(classes))\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_ids) / self.batch_size))  # âœ… FIXED\n",
    "\n",
    "# Create training and validation generators\n",
    "train_generator = ObjectDetectionDataGenerator(train_annotations, train_image_dir, max_objects=8)\n",
    "val_generator = ObjectDetectionDataGenerator(val_annotations, valid_image_dir, max_objects=8)\n",
    "\n",
    "# Use dynamically determined max_objects\n",
    "max_objects = train_generator.max_objects  \n",
    "\n",
    "def build_model(input_shape=(640, 640, 3), max_objects=max_objects):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)  # Replaces Flatten()\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    \n",
    "    # Bounding box output\n",
    "    bbox_output = layers.Dense(4 * max_objects, activation='sigmoid', name='bbox')(x)  \n",
    "    bbox_output = layers.Reshape((max_objects, 4))(bbox_output)  \n",
    "    \n",
    "    # Classification output\n",
    "    num_classes = len(set(ann['category_id'] for ann in train_annotations['annotations'])) + 1  # +1 for background class\n",
    "    print(f\"Number of classes (including background): {num_classes}\")\n",
    "    class_output = layers.Dense(max_objects * num_classes, activation='softmax')(x)\n",
    "    class_output = layers.Reshape((max_objects, num_classes), name='class')(class_output)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=[bbox_output, class_output])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'reshape': 'mse',  # Corrected name\n",
    "        'class': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "    },\n",
    "    metrics={\n",
    "        'reshape': ['mae'],  \n",
    "        'class': ['accuracy']\n",
    "    }\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=20,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model_save_path = \"../models/dental_fault_detector.h5\"\n",
    "model.save(model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "# Plot training history\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['class_accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_class_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Classification Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bb707e-5838-4db8-8627-e0ac64a9e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "#define test data\n",
    "\n",
    "test_image_dir = os.path.join(base_dir, \"test\")\n",
    "test_annotation_file = os.path.join(test_image_dir, \"_annotations.coco.json\")\n",
    "\n",
    "test_annotations = load_annotations(test_annotation_file)\n",
    "\n",
    "test_generator = ObjectDetectionDataGenerator(test_annotations, test_image_dir, max_objects=8)\n",
    "\n",
    "\n",
    "# Function to compute IoU (Intersection over Union)\n",
    "def compute_iou(box1, box2):\n",
    "    \"\"\" Compute Intersection over Union (IoU) between two bounding boxes. \"\"\"\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "\n",
    "    # Convert to (x_min, y_min, x_max, y_max)\n",
    "    box1 = [x1, y1, x1 + w1, y1 + h1]\n",
    "    box2 = [x2, y2, x2 + w2, y2 + h2]\n",
    "\n",
    "    # Compute intersection\n",
    "    xi1 = max(box1[0], box2[0])\n",
    "    yi1 = max(box1[1], box2[1])\n",
    "    xi2 = min(box1[2], box2[2])\n",
    "    yi2 = min(box1[3], box2[3])\n",
    "    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "\n",
    "    # Compute union\n",
    "    box1_area = w1 * h1\n",
    "    box2_area = w2 * h2\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "# Load model if not already in memory\n",
    "model = tf.keras.models.load_model(\"../models/dental_fault_detector.h5\")  # Replace with actual model path\n",
    "\n",
    "# Run model on test dataset\n",
    "test_images, test_labels = next(iter(test_generator))  # Load test batch, (Only one batch, change to loop over all test dataset if more than 32 images)\n",
    "predictions = model.predict(test_images)\n",
    "\n",
    "# Extract predicted bounding boxes and class labels\n",
    "pred_bboxes, pred_classes = predictions  # Shape: (batch_size, max_objects, 4) & (batch_size, max_objects, num_classes)\n",
    "true_bboxes, true_classes = test_labels   # Ground truth\n",
    "\n",
    "# Convert softmax class outputs to actual labels\n",
    "pred_classes = np.argmax(pred_classes, axis=-1)  # (batch_size, max_objects)\n",
    "\n",
    "# Compute bounding box regression error (MAE)\n",
    "mae_bbox = np.mean(np.abs(pred_bboxes - true_bboxes))\n",
    "\n",
    "# Compute IoU for bounding box predictions\n",
    "ious = []\n",
    "for i in range(len(test_images)):  # Loop over batch\n",
    "    for j in range(pred_bboxes.shape[1]):  # Loop over objects\n",
    "        iou = compute_iou(pred_bboxes[i][j], true_bboxes[i][j])\n",
    "        ious.append(iou)\n",
    "\n",
    "mean_iou = np.mean(ious)\n",
    "\n",
    "# Compute classification accuracy\n",
    "true_classes_flat = true_classes.flatten()\n",
    "pred_classes_flat = pred_classes.flatten()\n",
    "\n",
    "accuracy = accuracy_score(true_classes_flat, pred_classes_flat)\n",
    "f1 = f1_score(true_classes_flat, pred_classes_flat, average=\"weighted\", labels=np.unique(true_classes_flat))\n",
    "\n",
    "# Print Evaluation Metrics\n",
    "print(f\"Bounding Box Regression MAE: {mae_bbox:.4f}\")\n",
    "print(f\"Mean IoU: {mean_iou:.4f}\")\n",
    "print(f\"Classification Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Visualise Predictions\n",
    "def plot_predictions(images, true_bboxes, pred_bboxes, true_classes, pred_classes, num_samples=5):\n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 5))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(images[i].astype(\"uint8\"))\n",
    "        \n",
    "        # True Bounding Box (Green)\n",
    "        for j in range(true_bboxes.shape[1]):  # Loop over objects\n",
    "            x, y, w, h = true_bboxes[i][j]\n",
    "            rect = plt.Rectangle((x, y), w, h, edgecolor=\"green\", linewidth=2, fill=False)\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(x, y - 5, f\"True: {true_classes[i][j]}\", color=\"green\", fontsize=8)\n",
    "        \n",
    "        # Predicted Bounding Box (Red)\n",
    "        for j in range(pred_bboxes.shape[1]):\n",
    "            x, y, w, h = pred_bboxes[i][j]\n",
    "            rect = plt.Rectangle((x, y), w, h, edgecolor=\"red\", linewidth=2, fill=False)\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(x, y - 15, f\"Pred: {pred_classes[i][j]}\", color=\"red\", fontsize=8)\n",
    "        \n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Display some predictions\n",
    "plot_predictions(test_images, true_bboxes, pred_bboxes, true_classes, pred_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c854950d-a6c2-41d1-bc64-54e7db5a93a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "# Load ground truth annotations (COCO format)\n",
    "gt_annotations_path = val_annotation_file  # Path to validation annotations JSON\n",
    "coco_gt = COCO(gt_annotations_path)\n",
    "\n",
    "print(f\"COCO Categories: {coco_gt.getCatIds()}\")\n",
    "pred_category_ids = {p[\"category_id\"] for p in predictions}\n",
    "print(f\"Predicted Categories: {pred_category_ids}\")\n",
    "print(\"COCO Category Mapping:\", coco_gt.cats)\n",
    "\n",
    "\n",
    "# Collect predictions in COCO format\n",
    "predictions = []\n",
    "\n",
    "for batch_images, (batch_boxes, batch_classes) in val_generator:\n",
    "    pred_boxes, pred_classes_raw = model.predict(batch_images)\n",
    "\n",
    "    # Convert class probabilities to actual class IDs\n",
    "    pred_classes = np.argmax(pred_classes_raw, axis=-1)  # Shape: (batch_size, max_objects)\n",
    "    scores = np.max(pred_classes_raw, axis=-1)  # Get the highest probability per object\n",
    "\n",
    "    # Iterate over batch\n",
    "    for i, image_id in enumerate(batch_images):  # âœ… Ensure correct image tracking\n",
    "        for j, box in enumerate(pred_boxes[i]):\n",
    "            x, y, w, h = box  # COCO expects [x, y, width, height]\n",
    "\n",
    "            predictions.append({\n",
    "                \"image_id\": int(val_generator.image_ids[i]),  # âœ… Ensure correct mapping\n",
    "                \"category_id\": int(pred_classes[i][j]),  # âœ… Convert to scalar\n",
    "                \"bbox\": [float(x), float(y), float(w), float(h)],\n",
    "                \"score\": float(scores[i][j])  # âœ… Use real confidence score\n",
    "            })\n",
    "\n",
    "# Save predictions as a JSON file\n",
    "predictions_path = \"predictions.json\"\n",
    "with open(predictions_path, \"w\") as f:\n",
    "    json.dump(predictions, f)\n",
    "\n",
    "# Load predictions into COCO API\n",
    "coco_dt = coco_gt.loadRes(predictions_path)\n",
    "\n",
    "# Initialize COCO evaluation\n",
    "coco_eval = COCOeval(coco_gt, coco_dt, \"bbox\")\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()\n",
    "\n",
    "# Extract mAP@50 and mAP@75\n",
    "mAP_50 = coco_eval.stats[1]  # AP@IoU=0.50\n",
    "mAP_75 = coco_eval.stats[2]  # AP@IoU=0.75\n",
    "\n",
    "print(f\"mAP@50: {mAP_50:.4f}\")\n",
    "print(f\"mAP@75: {mAP_75:.4f}\")\n",
    "\n",
    "\n",
    "coco_eval.params.iouThrs = np.linspace(0.1, 0.5, 5)  # Instead of 0.5 to 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ae819-34e8-47eb-a645-d5a7b7f6db94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of pred_classes[{i}][{j}]:\", pred_classes[i][j].shape)\n",
    "print(f\"Value of pred_classes[{i}][{j}]:\", pred_classes[i][j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8664290d-47c2-495e-bf24-b1a51739d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    \"\"\"Compute IoU between two bounding boxes\"\"\"\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "\n",
    "    # Convert width/height to x2/y2\n",
    "    x1b, y1b, x2b, y2b = x1, y1, x1 + w1, y1 + h1\n",
    "    x1g, y1g, x2g, y2g = x2, y2, x2 + w2, y2 + h2\n",
    "\n",
    "    # Compute intersection\n",
    "    xi1, yi1, xi2, yi2 = max(x1b, x1g), max(y1b, y1g), min(x2b, x2g), min(y2b, y2g)\n",
    "    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "\n",
    "    # Compute union\n",
    "    box1_area = (x2b - x1b) * (y2b - y1b)\n",
    "    box2_area = (x2g - x1g) * (y2g - y1g)\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "    return inter_area / union_area if union_area > 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3552bb37-4522-4274-9d08-42ec4df35d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated predictions (you would replace this with actual model predictions)\n",
    "predicted_annotations = [...]  # List of predicted bounding boxes with 'category_id'\n",
    "\n",
    "iou_per_class = {cat_id: [] for cat_id in class_counts.keys()}\n",
    "\n",
    "for ann in annotations:\n",
    "    true_box = ann['bbox']\n",
    "    category_id = ann['category_id']\n",
    "\n",
    "    # Find the best-matching predicted box (dummy example, replace with model output)\n",
    "    best_iou = 0\n",
    "    for pred in predicted_annotations:\n",
    "        if pred['category_id'] == category_id:\n",
    "            iou = compute_iou(true_box, pred['bbox'])\n",
    "            best_iou = max(best_iou, iou)\n",
    "\n",
    "    iou_per_class[category_id].append(best_iou)\n",
    "\n",
    "# Compute mean IoU per class\n",
    "print(\"\\nMean IoU Per Class:\")\n",
    "for class_id, ious in iou_per_class.items():\n",
    "    mean_iou = np.mean(ious) if ious else 0\n",
    "    print(f\"{categories[class_id]}: Mean IoU = {mean_iou:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd5aa80-50b3-40fa-b415-18fbc088c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_dt = coco_gt.loadRes(predictions_path)\n",
    "print(f\"Loaded {len(coco_dt.anns)} predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b4270c-e339-4eb3-9cf8-57a3d5d5ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_eval.params.iouThrs = np.linspace(0.1, 0.5, 5)  # Test lower IoU thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d34c4fa-a613-4c3f-9222-4020c2c6c21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "for i, img_path in enumerate(val_generator.image_paths[:5]):  \n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(img)\n",
    "\n",
    "    # Draw ground truth boxes (GREEN)\n",
    "    for box in val_generator.gt_boxes[i]:\n",
    "        x, y, w, h = box\n",
    "        plt.gca().add_patch(plt.Rectangle((x, y), w, h, fill=False, edgecolor=\"green\", linewidth=2))\n",
    "\n",
    "    # Draw predicted boxes (RED)\n",
    "    for box in pred_boxes[i]:\n",
    "        x, y, w, h = box\n",
    "        plt.gca().add_patch(plt.Rectangle((x, y), w, h, fill=False, edgecolor=\"red\", linewidth=2))\n",
    "\n",
    "    plt.title(f\"Image {i}: Green = GT, Red = Predicted\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd6a340-3f23-4b4c-9cb2-ed533ae5e568",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
